{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jbdlb/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import datasets\n",
    "from datasets import Dataset, load_dataset\n",
    "from transformers import RobertaForSequenceClassification, RobertaTokenizerFast,TrainingArguments, Trainer\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import numpy as np\n",
    "import utils\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "utils.seed_everything()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-5b03ef3722775437\n",
      "Reusing dataset csv (/home/jbdlb/.cache/huggingface/datasets/csv/default-5b03ef3722775437/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0)\n"
     ]
    }
   ],
   "source": [
    "dataset=load_dataset(\"csv\", data_files={\"train\":\"../Journal-Finder/train.csv\",\n",
    "                                        \"valid\":\"../Journal-Finder/validation.csv\",\n",
    "                                        \"test\":\"../Journal-Finder/test.csv\"})\n",
    "\n",
    "# The validation set is not given"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():        # use the GPU.    \n",
    "    device = torch.device(\"cuda\")    \n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/jbdlb/.cache/huggingface/datasets/csv/default-5b03ef3722775437/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0/cache-7c0ae1447394e741.arrow\n",
      "Loading cached processed dataset at /home/jbdlb/.cache/huggingface/datasets/csv/default-5b03ef3722775437/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0/cache-704263e8686b6139.arrow\n",
      "Loading cached processed dataset at /home/jbdlb/.cache/huggingface/datasets/csv/default-5b03ef3722775437/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0/cache-6d5c6f797e87293d.arrow\n"
     ]
    }
   ],
   "source": [
    "# define an input as <article_title> : <article_abstract>\n",
    "dataset=dataset.map(lambda x: {\"input\":x[\"title\"]+\" : \"+x[\"abstract\"]},remove_columns=[\"abstract\",\"title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mapping labels to journal_id\n",
    "labels_jid_map = pd.DataFrame(dataset[\"train\"][\"journal_id\"],dataset[\"train\"][\"labels\"])\n",
    "labels_jid_map=labels_jid_map.groupby(0, group_keys=False).apply(lambda df: df.sample(1))\n",
    "labels_jid_map=labels_jid_map.to_dict()[0]\n",
    "num_labels=len(labels_jid_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mapping journal_id to journal_name\n",
    "with open('../Journal-Finder/mapping_id_journal_name.pickle', 'rb') as handle:\n",
    "    jid_jname_map = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scilitbert_tokenizer = RobertaTokenizerFast(\n",
    "    \"../ScilitBERT/ScilitBERT_tokenizer/scilitBERT_tok-vocab.json\",\n",
    "    \"../ScilitBERT/ScilitBERT_tokenizer/scilitBERT_tok-merges.txt\",\n",
    "    max_len=512\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../ScilitBERT/ScilitBERT_cased were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.decoder.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at ../ScilitBERT/ScilitBERT_cased and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# load the model\n",
    "ScilitBERT = RobertaForSequenceClassification.from_pretrained(\"../ScilitBERT/ScilitBERT_cased\",num_labels=num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/jbdlb/.cache/huggingface/datasets/csv/default-5b03ef3722775437/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0/cache-d00f590d94f54987.arrow\n",
      "Loading cached processed dataset at /home/jbdlb/.cache/huggingface/datasets/csv/default-5b03ef3722775437/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0/cache-af1c3e7aa2c9da9a.arrow\n",
      "Loading cached processed dataset at /home/jbdlb/.cache/huggingface/datasets/csv/default-5b03ef3722775437/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0/cache-194cbcf3655cfbca.arrow\n",
      "  0%|          | 100/73340 [01:34<19:14:50,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.5619, 'learning_rate': 2.9979533360622187e-05, 'epoch': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 200/73340 [03:09<19:13:27,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.6587, 'learning_rate': 2.993860008186656e-05, 'epoch': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 300/73340 [04:44<19:16:44,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.384, 'learning_rate': 2.989766680311093e-05, 'epoch': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 400/73340 [06:18<19:02:38,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.2515, 'learning_rate': 2.9856733524355304e-05, 'epoch': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 500/73340 [07:52<18:59:13,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.0769, 'learning_rate': 2.9815800245599673e-05, 'epoch': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 600/73340 [09:27<18:58:32,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.0276, 'learning_rate': 2.9774866966844045e-05, 'epoch': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 700/73340 [11:02<18:57:10,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.9505, 'learning_rate': 2.9733933688088418e-05, 'epoch': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 800/73340 [12:36<18:54:41,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.7945, 'learning_rate': 2.969300040933279e-05, 'epoch': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 900/73340 [14:10<18:58:30,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.6154, 'learning_rate': 2.965206713057716e-05, 'epoch': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|â–         | 939/73340 [14:47<18:55:44,  1.06it/s]"
     ]
    }
   ],
   "source": [
    "trainer, preds = utils.fine_tune(scilitbert_tokenizer,ScilitBERT,dataset,\"fine_tuning_demo_journal_finder\",output_dir=\"../results/fine_tuning_demo_journal_finder/\",log_dir=\"../logs/fine_tuning_demo_journal_finder\",num_labels=num_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('tf-gpu': conda)",
   "name": "python388jvsc74a57bd020ccc086250a1d8afb8ee213eb423490fc73b5d8661b0c9d3ae0954e46a7b6d9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "metadata": {
   "interpreter": {
    "hash": "20ccc086250a1d8afb8ee213eb423490fc73b5d8661b0c9d3ae0954e46a7b6d9"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}