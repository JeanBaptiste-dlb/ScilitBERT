# ScilitBERT Example

In this repository you will find a Jupyter notebook explaining how to load ScilitBERT and its tokenizer using HugginFace, and how to test the Mask filling feature. Additionally, we provide a dataset for fine-tuning on the Journal Finder task and a notebook to quick start the fine-tuning.

## What is ScilitBERT?

ScilitBERT is a BERT model for academic language representation developed by [MDPI](https://www.mdpi.com/). The training data is extracted from [Scilit](https://www.scilit.net/)

## Getting started

+ You can download a zip file containing ScilitBERT pretrained and its tokenizer at the link bellow:

to run the notebook you can unzip the downloaded file in the root of this repository.

+ You can now run the notebook: [notebooks/example_mlm.ipynb](./notebooks/example_mlm.ipynb)

## Fine-Tuning on the Journal Finder task

+ You can try to fine-tune the model on the Journal Finder task, the dataset is available at the link bellow:
+ We add a basic fine-tuning example notebook:
